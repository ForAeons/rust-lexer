# Lexer in Rust

This repository contains a simple lexer implemented in Rust. The lexer is designed to tokenize input strings, converting them into a sequence of tokens that can be further processed or analyzed.

## Features

- Tokenization of various lexeme types including identifiers, literals, punctuation, operators, and more.
- Support for numeric literals.
- Skipping of whitespace to focus on significant tokens.
